{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET DATA\n",
    "df = pd.read_csv(\"mutations_1.csv\")\n",
    "df = df.set_index('class')\n",
    "df = df.loc[:, (df != 0).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLASSIFICATION PER MUTATION\n",
    "def classify_row(row, mutation, group_a, group_b):\n",
    "    if row[mutation] == 1:\n",
    "        group_a.append(row.name)\n",
    "    if row[mutation] == 0:\n",
    "        group_b.append(row.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TREE BUILDER\n",
    "def build_tree(df, level, used_mutations=[], group=[]):\n",
    "    \n",
    "    #IF ROOT, EMPTY USED MUTATIONS AND SELECT ALL SAMPLES\n",
    "    if len(group) == 0:\n",
    "        used_mutations=[]\n",
    "        group = list(df.index)\n",
    "\n",
    "    #CALCULATING PHI FUNCTION THROUGH PANDAS (LOOKS BAD BUT EXTREMLY PERFORMATIC)     \n",
    "    df_classification = pd.DataFrame(index=list(df.columns), columns=[])\n",
    "\n",
    "    df_classification['NTL'] = df.sum()\n",
    "    df_classification['NTR'] = len(df)-df_classification['NTL']\n",
    "    df_classification['NTL_C'] = df[df.index.str.startswith('C')].sum()\n",
    "    df_classification['NTL_NC'] = df[df.index.str.startswith('NC')].sum()\n",
    "    df_classification['NTR_C'] = len(df[df.index.str.startswith('C')])-df[df.index.str.startswith('C')].sum()\n",
    "    df_classification['NTR_NC'] = len(df[df.index.str.startswith('NC')])-df[df.index.str.startswith('NC')].sum()\n",
    "    df_classification['PL'] = df_classification['NTL']/len(df)\n",
    "    df_classification['PR'] = df_classification['NTR']/len(df)\n",
    "    df_classification['PCTL'] = df_classification['NTL_C']/df_classification['NTL']\n",
    "    df_classification['PNCTL'] = df_classification['NTL_NC']/df_classification['NTL']\n",
    "    df_classification['PCTR'] = df_classification['NTR_C']/df_classification['NTR']\n",
    "    df_classification['PNCTR'] = df_classification['NTR_NC']/df_classification['NTR']\n",
    "    df_classification['QST'] = np.abs(df_classification['PCTL']-df_classification['PCTR']) + np.abs(df_classification['PNCTL']-df_classification['PNCTR'])\n",
    "    df_classification['2PLPR'] = 2*df_classification['PL']*df_classification['PR']\n",
    "    df_classification['PHI'] = df_classification['2PLPR']*df_classification['QST']\n",
    "    df_classification.sort_values(by='PHI', ascending=False, inplace=True)\n",
    "\n",
    "    #VERIFY IF MUTATION HAS BEEN USED\n",
    "    unused_mutations = [m for m in df_classification.index if m not in used_mutations]\n",
    "\n",
    "    #SELECTED ONLY SQRT(N) BEST MUTATIONS\n",
    "    sqrt_n = int(np.sqrt(len(unused_mutations)))\n",
    "    unused_mutations = unused_mutations[:sqrt_n]\n",
    "    \n",
    "    if not unused_mutations:\n",
    "        return None\n",
    "\n",
    "    group_a = []\n",
    "    group_b = []\n",
    "    \n",
    "    #RANDOMIZE 2/3 OF N OUT OF THE SQRT(N) BEST MUTATIONS\n",
    "    np.random.shuffle(unused_mutations)\n",
    "    filter = int(2 * len(unused_mutations)/3)\n",
    "    selected_mutations = unused_mutations[:filter]\n",
    "\n",
    "    #SELECTING BEST MUTATION AND SPLITTING GROUPS\n",
    "    best_mutation = max(selected_mutations, key=lambda mutation: df_classification.loc[mutation, 'PHI'] if not pd.isna(df_classification.loc[mutation, 'PHI']) else float('-inf'))\n",
    "    used_mutations.append(best_mutation)\n",
    "\n",
    "    df.apply(classify_row, args = (best_mutation, group_a, group_b), axis=1)\n",
    "    group_a = list(set(group_a))\n",
    "    group_b = list(set(group_b))\n",
    "\n",
    "    level = level - 1\n",
    "\n",
    "    if level == 0:\n",
    "        return {'mutation': best_mutation, 'group_a': group_a, 'group_b': group_b}\n",
    "    \n",
    "    #RECURSIVELY BUILD NEXT LEVELS\n",
    "    tree_a = build_tree(df.loc[group_a], level, used_mutations, group_a)\n",
    "    tree_b = build_tree(df.loc[group_b], level, used_mutations, group_b)\n",
    "    \n",
    "    return {'mutation': best_mutation, 'group_a': tree_a, 'group_b': tree_b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mutations:  ['DOCK3_GRCh37_3:51417604-51417604_Frame-Shift-Del_DEL_C-C--', 'RNF43_GRCh37_17:56435161-56435161_Frame-Shift-Del_DEL_C-C--', 'RPL22_GRCh37_1:6257785-6257785_Frame-Shift-Del_DEL_T-T--', \"CSNK1G1_GRCh37_15:64461260-64461260_3'UTR_DEL_A-A--\", 'PPP2R1A_GRCh37_19:52715971-52715971_Missense-Mutation_SNP_C-C-G_C-C-T', \"NFIA_GRCh37_1:61543223-61543223_5'Flank_DEL_A-A--\", 'KRAS_GRCh37_12:25398284-25398284_Missense-Mutation_SNP_C-C-A_C-C-T_C-C-G']\n",
      "Number of times each feature was selected as root, respectively [4, 6, 18, 1, 4, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#BUILD RANDOM FOREST\n",
    "def random_forest(n_trees, levels, df):\n",
    "    trees = []\n",
    "    root_nodes = []\n",
    "    for n in range(n_trees):\n",
    "        df_bootstrap = df.sample(n=len(df), replace=True)\n",
    "        if n == 0:\n",
    "            test_samples = [i for i in df.index if i not in df_bootstrap.index]\n",
    "        tree = build_tree(df_bootstrap, levels)\n",
    "        trees.append(tree)\n",
    "        root_nodes.append(tree['mutation'])\n",
    "    return trees, root_nodes, test_samples\n",
    "\n",
    "trees, roots, test_samples = random_forest(35, 10, df)\n",
    "\n",
    "#RANDOM FOREST REPORT\n",
    "def get_feature_count(level):\n",
    "    features = []\n",
    "    feature_count = []\n",
    "    for feature in level:\n",
    "        if feature not in features:\n",
    "            features.append(feature)\n",
    "            feature_count.append(1)\n",
    "        else:\n",
    "            index = features.index(feature)\n",
    "            feature_count[index] += 1\n",
    "    return features, feature_count\n",
    "\n",
    "print(\"Root mutations: \", get_feature_count(roots)[0])\n",
    "print(\"Number of times each feature was selected as root, respectively\", get_feature_count(roots)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST CLASSIFIER\n",
    "\n",
    "#MULTI-LEVEL CLASSIFIER\n",
    "def tree_classifier(sample, tree):\n",
    "    current_node = tree\n",
    "    while 'mutation' in current_node:\n",
    "        mutation = current_node['mutation']\n",
    "        if sample[mutation] == 1:\n",
    "            current_node = current_node['group_a']\n",
    "        else:\n",
    "            current_node = current_node['group_b']\n",
    "    counter = sum(1 for value in current_node if value.startswith('C'))\n",
    "    if len(current_node) / 2 < counter:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#RANDOM FOREST CLASSIFIER            \n",
    "def random_forest_classification(sample, trees):\n",
    "    classification = 0\n",
    "    for i in range(len(trees)):\n",
    "        classification += tree_classifier(sample, trees[i])\n",
    "    if classification < len(trees)/2:\n",
    "        return 0, classification\n",
    "    else:\n",
    "        return 1, classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample  C1  is C, with  22  trees classifying it as C\n",
      "Sample  C10  is NC, with  21  trees classifying it as NC\n",
      "Sample  C50  is C, with  32  trees classifying it as C\n",
      "Sample  NC5  is NC, with  35  trees classifying it as NC\n",
      "Sample  NC15  is NC, with  35  trees classifying it as NC\n",
      "\n",
      "METRICS FOR ALL SAMPLES TRAINED AND TESTED\n",
      "Accuracy (How many samples were properly labeled):  89.6 %\n",
      "Sensitivity (How many positive samples were identified):  75.93 %\n",
      "Specificity (How many negative samples were identified):  100.0 %\n",
      "Precision (How many positive labels are correct):  100.0 %\n",
      "Miss Rate (How many positive samples were not detected):  24.07 %\n",
      "False Discovery Rate (How many samples that were labeled positive are negative):  0.0 %\n",
      "False Omission Rate (How many samples that were labeled negative are positive):  15.48 %\n",
      "\n",
      "METRICS FOR TEST SAMPLES (1ST TREE OUT OF BAG SAMPLES)\n",
      "Accuracy (How many samples were properly labeled):  91.21 %\n",
      "Sensitivity (How many positive samples were identified):  73.33 %\n",
      "Specificity (How many negative samples were identified):  100.0 %\n",
      "Precision (How many positive labels are correct):  100.0 %\n",
      "Miss Rate (How many positive samples were not detected):  26.67 %\n",
      "False Discovery Rate (How many samples that were labeled positive are negative):  0.0 %\n",
      "False Omission Rate (How many samples that were labeled negative are positive):  11.59 %\n"
     ]
    }
   ],
   "source": [
    "#REQUESTED CLASSIFICAIONS\n",
    "for sample in ['C1', 'C10', 'C50', 'NC5', 'NC15']:\n",
    "    classification, votes = random_forest_classification(df.loc[sample], trees)\n",
    "    if classification == 0:\n",
    "        print(\"Sample \", sample, \" is NC, with \", len(roots)-votes, \" trees classifying it as NC\")\n",
    "    else:\n",
    "        print(\"Sample \", sample, \" is C, with \", votes, \" trees classifying it as C\")\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for sample in list(df.index):\n",
    "    classification = random_forest_classification(df.loc[sample], trees)[0]\n",
    "    if classification and sample.startswith('C'):\n",
    "        TP+=1\n",
    "    if classification and sample.startswith('NC'):\n",
    "        FP+=1\n",
    "    if not classification and sample.startswith('C'):\n",
    "        FN+=1\n",
    "    if not classification and sample.startswith('NC'):\n",
    "        TN+=1\n",
    "\n",
    "accuracy = round((TP+TN)/(TP+TN+FP+FN)*100,2)\n",
    "sensitivity = round((TP)/(TP+FN)*100,2)\n",
    "specificity = round((TN)/(TN+FP)*100,2)\n",
    "precision = round((TP)/(TP+FP)*100,2)\n",
    "fdr = round((FP)/(TP+FP)*100,2)\n",
    "miss_rate = round((FN)/(TP+FN)*100,2)\n",
    "false_or = round((FN)/(TN+FN)*100,2)\n",
    "\n",
    "print(\"\")\n",
    "print(\"METRICS FOR ALL SAMPLES TRAINED AND TESTED\")\n",
    "print(\"Accuracy (How many samples were properly labeled): \", accuracy, \"%\")\n",
    "print(\"Sensitivity (How many positive samples were identified): \", sensitivity, \"%\")\n",
    "print(\"Specificity (How many negative samples were identified): \", specificity, \"%\")\n",
    "print(\"Precision (How many positive labels are correct): \", precision, \"%\")\n",
    "print(\"Miss Rate (How many positive samples were not detected): \", miss_rate, \"%\")\n",
    "print(\"False Discovery Rate (How many samples that were labeled positive are negative): \", fdr, \"%\")\n",
    "print(\"False Omission Rate (How many samples that were labeled negative are positive): \", false_or, \"%\")\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for sample in list(test_samples):\n",
    "    classification = random_forest_classification(df.loc[sample], trees)[0]\n",
    "    if classification and sample.startswith('C'):\n",
    "        TP+=1\n",
    "    if classification and sample.startswith('NC'):\n",
    "        FP+=1\n",
    "    if not classification and sample.startswith('C'):\n",
    "        FN+=1\n",
    "    if not classification and sample.startswith('NC'):\n",
    "        TN+=1\n",
    "\n",
    "accuracy = round((TP+TN)/(TP+TN+FP+FN)*100,2)\n",
    "sensitivity = round((TP)/(TP+FN)*100,2)\n",
    "specificity = round((TN)/(TN+FP)*100,2)\n",
    "precision = round((TP)/(TP+FP)*100,2)\n",
    "fdr = round((FP)/(TP+FP)*100,2)\n",
    "miss_rate = round((FN)/(TP+FN)*100,2)\n",
    "false_or = round((FN)/(TN+FN)*100,2)\n",
    "\n",
    "print(\"\")\n",
    "print(\"METRICS FOR TEST SAMPLES (1ST TREE OUT OF BAG SAMPLES)\")\n",
    "print(\"Accuracy (How many samples were properly labeled): \", accuracy, \"%\")\n",
    "print(\"Sensitivity (How many positive samples were identified): \", sensitivity, \"%\")\n",
    "print(\"Specificity (How many negative samples were identified): \", specificity, \"%\")\n",
    "print(\"Precision (How many positive labels are correct): \", precision, \"%\")\n",
    "print(\"Miss Rate (How many positive samples were not detected): \", miss_rate, \"%\")\n",
    "print(\"False Discovery Rate (How many samples that were labeled positive are negative): \", fdr, \"%\")\n",
    "print(\"False Omission Rate (How many samples that were labeled negative are positive): \", false_or, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP BY STEP RANDOM FOREST IMPROVEMENT PLAN\n",
    "\n",
    "1. Make it a dynamic-level trees random forest. Instead of 2, build it multi-level. Evaluate how many levels perform the better. -> 8 levels generate a good balance between evaluation quality/performance. $\\checkmark$\n",
    "2. Filter the $\\sqrt{n}$ best mutations given by Gain or $\\phi$ function. $\\checkmark$\n",
    "3. Randomnly select $\\frac{2n}{3}$ mutations out of the best $\\sqrt{n}$ selected on the previous step. This should give us $\\frac{2\\sqrt{n}}{3}$ mutations among the best ones according to our quality functions to be selected by the tree. $\\checkmark$\n",
    "4. Before selecting the features, drop samples that don't contain any of the selected $\\sqrt{n}$ features form step 2, so they don't impact our forest build. Report removed samples. - Drastically decrease accuracy, thus not implemented $X$\n",
    "5. Increase number of trees, or evaluate what number of trees generate a better evaluation - 35 trees. $\\checkmark$\n",
    "6. Evaluate forest performance with gain or $\\phi$ function, and see which of them performs better according to metrics. - performance is similar, but $\\phi$ function is less sucessitible to errors. With multi-level trees we will comonly reach empty nodes that will cause division by zero issues with gain, thus $\\phi$ was used $\\checkmark$\n",
    "7. Remove useless features - Features that are negative for all samples. $\\checkmark$\n",
    "8. Report the five elements assigned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are we trying to discover about cancer?\n",
    "\n",
    "    -> We are developing a methodology of detecting cancer giving a set of possible mutations present in a person.\n",
    "    \n",
    "    -> By developing a tree we can use mutations to filter specific situations in which you are able with some certain affirm if a patient have or not cancer\n",
    "\n",
    "2. What have you discovered about cancer?\n",
    "\n",
    "    -> Cancer is directly related to some mutations such as RPL, RNF, KRAS, DOCK3, PPP etc. Furthermore, we are able to observe mutations that are correlated to cancer either positively or negatively.\n",
    "\n",
    "3. Describe your software design:\n",
    "\n",
    "    -> Get the data\n",
    "\n",
    "    -> Manipulate the data and clear \"useless\" features\n",
    "\n",
    "    -> Define a function that evaluates a set of given samples for a given mutation\n",
    "\n",
    "    -> Define phi function that will use to determine the mutations to split the given node of a tree\n",
    "\n",
    "    -> Select $\\frac{2n}{3}$ out of the best $\\sqrt{n}$ mutations in a given node, without reusing any mutation\n",
    "\n",
    "    -> Recursively do it for all levels of the tree\n",
    "\n",
    "    -> Build 35 trees with different bootstrap samples, and observe which mutations were chosen as roots\n",
    "\n",
    "    -> Build a classifier for each tree, ann create a function that goes over it for every tree to use it as a random forest classifier\n",
    "\n",
    "    -> Evaluate the quality of the forest according to the metrics\n",
    "\n",
    "5. How does your findings apply to cancer research?\n",
    "    -> We can use this algorithm developed on this program to study people who could potentially give cancer and have a better idea on how to identify cancer patients.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
